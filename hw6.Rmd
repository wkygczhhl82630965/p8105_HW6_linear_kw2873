---
title: "hw6"
author: "Keyi Wang"
date: "11/20/2019"
output: github_document
---

```{r setup, include=FALSE}
set.seed(10)

# load library
library(tidyverse)
library(viridis)
library(ggridges)
library(patchwork)
library(rvest)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  # display the code in the code truck above its results in the final document
  echo = TRUE,
  # do not display any warning messages generated by the code
  warning = FALSE,
  # set the figure to be 8 x 6, and the proportion it takes to be 90%
  fig.width = 8,
  fig.height = 6, 
  out.width = "90%"
)

# setting a global options for continuous data color family and a different format to set discrete data to have a color family
options(
  ggplot2.countinuous.colour = "viridis",
  ggplot2.countinuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

# have a minimal theme and legends at the bottom
theme_set(theme_get() + theme(legend.position = "bottom"))
```
# Problem 1-part1

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.)
```{r}
birthweight = 
  read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names()  %>%
   mutate(
    babysex = as.factor(case_when(
       babysex == 1 ~ "male",
       babysex == 2 ~ "female",
    )),
    frace = as.factor(case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other",
      frace == 9 ~ "Unknown",
    )),
    malform = as.factor(case_when(
      malform == 0 ~ "absent",
      malform == 1 ~ "present"
    )),
    mrace = as.factor(case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other",
    ))
  )

## check for missing data
colMeans(is.na(birthweight)) %>% 
  knitr::kable()

```

Therefore, there is no missing data.



Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.
```{r}

full = lm(bwt ~ ., data = birthweight)
summary(full)
```


```{r}
hypo_model = function(df) {
  lm(bwt ~ bhead + blength + delwt + menarche , data = birthweight)}

weight_model = hypo_model(birthweight)

  
birthweight %>% 
  add_predictions(weight_model) %>% 
  add_residuals(weight_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
    geom_point(alpha = 0.3,color = "orange") +
  labs(
        title = "Hypothesized Regression Model: Predicted Values vs Residuals",
        x = "Predicted Values",
        y = "Residuals"
      )

```
Since we want to build a model based on baby birthweight, I decided to choose several predictors that are quite relavent to baby birthweight, which are baby’s head circumference at birth, baby's length, mother’s weight at delivery and mother’s age at birth. 
As we can see in the above graph, there is a heavy cluster in the lower right corner, with a tail fanning out to the top left, which suggests that my model is not great. The residuals do not form a desired straight line across the range of the predicted values 

# part 2 
Compare your model to two others:
One using length at birth and gestational age as predictors (main effects only)
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

```{r}
## the smaller model
model_1 =lm(bwt ~ blength + gaweeks, data = birthweight )

## model with interactions
model_2 = lm(bwt ~ bhead + blength + babysex +
       (bhead * blength) + (bhead * babysex) + (blength * babysex) +
       (bhead * blength * babysex), data = birthweight)



## cross validation, split data and run three models on each split

cv_birthweight = 
  crossv_mc(birthweight, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))%>%
  mutate(hypo_model = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + parity + smoken, data = .x)),
         model_1  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         model_2 = map(train, ~lm(bwt ~ bhead + blength + babysex +
       (bhead * blength) + (bhead * babysex) + (blength * babysex) +
       (bhead * blength * babysex), data = .x))) %>% 
  mutate(rmse_proposed = map2_dbl(hypo_model, test, ~rmse(model = .x, data = .y)),
         rmse_main_effect = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
         rmse_interaction = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)))


## visualization
cv_birthweight %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin(alpha = 0.5) +
  labs(title = "Violin Plot of RMSE in Different Models",
       x = "Models",
       y = "Root Mean of Square Error") +
  theme(plot.title = element_text(hjust = 0.5))




```
Comments: 
When comparing the my own hypothesized, model 1 and the interaction models, I noticed that both the hypothesized model and model with interaction show relative smaller RMSE compared to the model 2. Model 2 has the highest RMSEs, suggesting a lot of modifications should be done to improve this model. 

# problem 2
```{r}

# loading data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```


```{r}
## r^2 part
bootstrap_samples = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    variables = map(models, broom::glance)
    ) %>% 
  select(-strap, -models) %>% 
  unnest(results, variables)

# calculate the 95% CI of r sqaure
CI_r2 = 
  bootstrap_samples %>% 
  filter(term == "tmin") %>% 
  pull(r.squared) %>% 
  quantile(., c(0.025, 0.975))

CI_r2
```

Therefore the 95% CI of r^2 is [`r CI_r2[[1]]`, `r CI_r2[[2]]`].


```{r}
# visualization for r^2
bootstrap_samples %>% 
  filter(term == "tmin") %>% 
  # make plot
  ggplot(aes(x = r.squared)) + 
  geom_histogram(aes(y = stat(count / sum(count))), stat = "density", fill = "darksalmon") +
  labs(
    title = "Distribution Plot of the Estimate of R square",
    x = "Estimate of R square",
    y = "Density") +
  geom_vline(aes(xintercept = mean(r.squared))) +
  geom_vline(aes(xintercept = CI_r2[[1]]), color = "darkgreen",linetype = "longdash") +
  geom_vline(aes(xintercept = CI_r2[[2]]), color = "darkgreen",linetype = "longdash") +
  theme(plot.title = element_text(hjust = 0.5))

```

Comments: According to the plot, we can see that this is close to normal curve. We can also tell from the CI that most of data were distributed around the center. Hence, we can say that the estimate is roughly distributed normally.


```{r}
# calculate the 95% CI of log(beta0_hat * beta1_hat)
beta_ci = 
  bootstrap_samples %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
    id_cols = .id,
    names_from = term,
    values_from = estimate
  ) %>% 
  janitor::clean_names() %>% 
  mutate(log_estimate = log(intercept * tmin)) %>% 
  pull(log_estimate) %>% 
  quantile(., c(0.025, 0.975))

# display
beta_ci
```
Therefore the 95% CI of is  [`r beta_ci[[1]]`, `r beta_ci[[2]]`]


```{r}
# visualization for log(beta0_hat * beta1_hat)
bootstrap_samples %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
    id_cols = .id,
    names_from = term,
    values_from = estimate
  ) %>% 
  janitor::clean_names() %>% 
  mutate(log_estimate = log(intercept * tmin)) %>% 
  #make plot
  ggplot(aes(x = log_estimate)) + 
  geom_histogram(aes(y = stat(count / sum(count))), stat = "density", fill = "darksalmon") +
  labs(
    title = "Distribution Plot of the Estimate of log(beta0_hat * beta1_hat)",
    x = "Estimate of log(beta0_hat * beta1_hat)",
    y = "Density") +
  
  geom_vline(aes(xintercept = mean(log_estimate))) +
  geom_vline(aes(xintercept = beta_ci[[1]]), color = "darkgreen",linetype = "longdash") +
  geom_vline(aes(xintercept = beta_ci[[2]]), color = "darkgreen",linetype = "longdash") +
  theme(plot.title = element_text(hjust = 0.5))
```

Comments: According to density plot, we can see that this is close to normal curve. We can also tell from the CI that most of data were distributed around the center. Hence, we can say that the estimate log(beta0_hat * beta1_hat) is roughly distributed normally. This density plot is not as “normal”/“belled” as r^2's distribution.







